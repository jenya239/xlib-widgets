# Directory content: src/ui/video_player/
# Generated on: 2025-03-10 17:34:42 +0400

================================================================================
FILE: src/ui/video_player/video_decoder.cppm
================================================================================

module;
#include <string>
#include <memory>
#include <vector>
#include <iostream>
extern "C" {
#include <libavcodec/avcodec.h>
#include <libavformat/avformat.h>
#include <libswscale/swscale.h>
#include <libavutil/imgutils.h>
}

export module ui.video_player.video_decoder;

import services.logger_service;

export class VideoDecoder {
private:
    std::shared_ptr<LoggerService> logger;
    AVFormatContext* formatContext = nullptr;
    AVCodecContext* codecContext = nullptr;
    AVFrame* frame = nullptr;
    AVFrame* frameRGB = nullptr;
    SwsContext* swsContext = nullptr;
    int videoStreamIndex = -1;
    uint8_t* buffer = nullptr;
    bool videoLoaded = false;
    int width = 0;
    int height = 0;
    int64_t duration = 0;

public:
    VideoDecoder() {
        logger = std::make_shared<LoggerService>();
        logger->info("VideoDecoder created");
    }

    ~VideoDecoder() {
        closeVideo();
    }

    bool loadVideo(const std::string& path) {
        // Закрываем предыдущее видео, если оно было открыто
        closeVideo();

        logger->info("Loading video: " + path);

        // Открываем файл
        formatContext = avformat_alloc_context();
        if (avformat_open_input(&formatContext, path.c_str(), nullptr, nullptr) != 0) {
            logger->error("Could not open video file: " + path);
            return false;
        }

        // Получаем информацию о потоках
        if (avformat_find_stream_info(formatContext, nullptr) < 0) {
            logger->error("Could not find stream information");
            closeVideo();
            return false;
        }

        // Находим видеопоток
        videoStreamIndex = -1;
        for (unsigned int i = 0; i < formatContext->nb_streams; i++) {
            if (formatContext->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
                videoStreamIndex = i;
                break;
            }
        }

        if (videoStreamIndex == -1) {
            logger->error("Could not find video stream");
            closeVideo();
            return false;
        }

        // Получаем кодек
        const AVCodec* codec = avcodec_find_decoder(formatContext->streams[videoStreamIndex]->codecpar->codec_id);
        if (!codec) {
            logger->error("Unsupported codec");
            closeVideo();
            return false;
        }

        // Создаем контекст кодека
        codecContext = avcodec_alloc_context3(codec);
        if (!codecContext) {
            logger->error("Could not allocate codec context");
            closeVideo();
            return false;
        }

        // Копируем параметры кодека
        if (avcodec_parameters_to_context(codecContext, formatContext->streams[videoStreamIndex]->codecpar) < 0) {
            logger->error("Could not copy codec parameters");
            closeVideo();
            return false;
        }

        // Открываем кодек
        if (avcodec_open2(codecContext, codec, nullptr) < 0) {
            logger->error("Could not open codec");
            closeVideo();
            return false;
        }

        // Получаем размеры видео
        width = codecContext->width;
        height = codecContext->height;
        duration = formatContext->duration;

        // Создаем фреймы
        frame = av_frame_alloc();
        frameRGB = av_frame_alloc();
        if (!frame || !frameRGB) {
            logger->error("Could not allocate frames");
            closeVideo();
            return false;
        }

        // Выделяем буфер для RGB данных
        int numBytes = av_image_get_buffer_size(AV_PIX_FMT_RGB24, width, height, 1);
        buffer = (uint8_t*)av_malloc(numBytes * sizeof(uint8_t));

        // Настраиваем frameRGB для использования этого буфера
        av_image_fill_arrays(frameRGB->data, frameRGB->linesize, buffer,
                            AV_PIX_FMT_RGB24, width, height, 1);

        // Создаем контекст для конвертации
        swsContext = sws_getContext(
            width, height, codecContext->pix_fmt,
            width, height, AV_PIX_FMT_RGB24,
            SWS_BILINEAR, nullptr, nullptr, nullptr
        );

        if (!swsContext) {
            logger->error("Could not initialize conversion context");
            closeVideo();
            return false;
        }

        videoLoaded = true;
        logger->info("Video loaded successfully. Width: " + std::to_string(width) +
                    ", Height: " + std::to_string(height));
        return true;
    }

    void closeVideo() {
        videoLoaded = false;

        if (buffer) {
            av_free(buffer);
            buffer = nullptr;
        }

        if (frameRGB) {
            av_frame_free(&frameRGB);
            frameRGB = nullptr;
        }

        if (frame) {
            av_frame_free(&frame);
            frame = nullptr;
        }

        if (codecContext) {
            avcodec_free_context(&codecContext);
            codecContext = nullptr;
        }

        if (formatContext) {
            avformat_close_input(&formatContext);
            formatContext = nullptr;
        }

        if (swsContext) {
            sws_freeContext(swsContext);
            swsContext = nullptr;
        }

        videoStreamIndex = -1;
        logger->info("Video resources released");
    }

    bool isLoaded() const {
        return videoLoaded;
    }

    int getWidth() const {
        return width;
    }

    int getHeight() const {
        return height;
    }

    int64_t getDuration() const {
        return duration;
    }

    // Получить первый кадр видео
    std::vector<uint8_t> getFirstFrame() {
        if (!videoLoaded) {
            logger->error("Cannot get first frame: video not loaded");
            return {};
        }

        // Перемотка в начало
        av_seek_frame(formatContext, videoStreamIndex, 0, AVSEEK_FLAG_BACKWARD);

        AVPacket packet;
        bool frameDecoded = false;

        // Читаем пакеты, пока не декодируем кадр
        while (av_read_frame(formatContext, &packet) >= 0 && !frameDecoded) {
            if (packet.stream_index == videoStreamIndex) {
                // Отправляем пакет декодеру
                int response = avcodec_send_packet(codecContext, &packet);
                if (response < 0) {
                    logger->error("Error sending packet to decoder");
                    av_packet_unref(&packet);
                    continue;
                }

                // Получаем декодированный кадр
                response = avcodec_receive_frame(codecContext, frame);
                if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {
                    av_packet_unref(&packet);
                    continue;
                } else if (response < 0) {
                    logger->error("Error during decoding");
                    av_packet_unref(&packet);
                    continue;
                }

                // Конвертируем кадр в RGB формат
                sws_scale(swsContext, frame->data, frame->linesize, 0,
                         height, frameRGB->data, frameRGB->linesize);

                frameDecoded = true;
            }
            av_packet_unref(&packet);
        }

        if (!frameDecoded) {
            logger->error("Could not decode first frame");
            return {};
        }

        // Копируем данные кадра в вектор
        int numBytes = av_image_get_buffer_size(AV_PIX_FMT_RGB24, width, height, 1);
        std::vector<uint8_t> frameData(buffer, buffer + numBytes);

        return frameData;
    }

    // Получить кадр по временной позиции (0.0 - 1.0)
    std::vector<uint8_t> getFrameAtPosition(float position) {
        if (!videoLoaded) {
            logger->error("Cannot get frame: video not loaded");
            return {};
        }

        // Вычисляем временную метку
        int64_t timestamp = static_cast<int64_t>(position * duration);

        // Перемотка к нужной позиции
        av_seek_frame(formatContext, videoStreamIndex, timestamp, AVSEEK_FLAG_BACKWARD);

        // Очищаем буферы декодера
        avcodec_flush_buffers(codecContext);

        AVPacket packet;
        bool frameDecoded = false;

        // Читаем пакеты, пока не декодируем кадр
        while (av_read_frame(formatContext, &packet) >= 0 && !frameDecoded) {
            if (packet.stream_index == videoStreamIndex) {
                // Отправляем пакет декодеру
                int response = avcodec_send_packet(codecContext, &packet);
                if (response < 0) {
                    logger->error("Error sending packet to decoder");
                    av_packet_unref(&packet);
                    continue;
                }

                // Получаем декодированный кадр
                response = avcodec_receive_frame(codecContext, frame);
                if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {
                    av_packet_unref(&packet);
                    continue;
                } else if (response < 0) {
                    logger->error("Error during decoding");
                    av_packet_unref(&packet);
                    continue;
                }

                // Конвертируем кадр в RGB формат
                sws_scale(swsContext, frame->data, frame->linesize, 0,
                         height, frameRGB->data, frameRGB->linesize);

                frameDecoded = true;
            }
            av_packet_unref(&packet);
        }

        if (!frameDecoded) {
            logger->error("Could not decode frame at position " + std::to_string(position));
            return {};
        }

        // Копируем данные кадра в вектор
        int numBytes = av_image_get_buffer_size(AV_PIX_FMT_RGB24, width, height, 1);
        std::vector<uint8_t> frameData(buffer, buffer + numBytes);

        return frameData;
    }
};

================================================================================
FILE: src/ui/video_player/video_player.cppm
================================================================================

module;
#include <vector>
#include <memory>
#include <string>
#include <algorithm> // For std::max and std::min
// X11 headers
#include <X11/Xlib.h>
#include <X11/Xft/Xft.h>
// FFmpeg headers
#include <libavformat/avformat.h>
#include <libavcodec/avcodec.h>
#include <libswscale/swscale.h>
// If you don't have AV_TIME_BASE defined, uncomment this:
// #define AV_TIME_BASE 1000000

export module ui.video_player.video_player;

import ui.widget;
import ui.render_buffer;
import ui.event;
import services.xdisplay_service;
import services.logger_service;
import core.ioc_container;
import ui.video_player.video_decoder;
import ui.video_player.video_renderer;

export class VideoPlayer : public Widget {
private:
    std::string videoPath;
    bool isPlaying = false;
    XftFont* font = nullptr;
    XftColor textColor;
    std::shared_ptr<LoggerService> logger;
    Display* currentDisplay = nullptr;

    // Добавляем переменные для отслеживания прогресса
    float currentPosition = 0.0f; // от 0.0 до 1.0
    int duration = 100; // Длительность видео в секундах (пока заглушка)

    // Области для элементов управления
    struct {
        int playButtonX, playButtonY;
        unsigned int playButtonWidth, playButtonHeight;

        int progressBarX, progressBarY;
        unsigned int progressBarWidth, progressBarHeight;
    } controls;

    // Добавляем декодер и рендерер
    std::unique_ptr<VideoDecoder> decoder;
    std::unique_ptr<VideoRenderer> renderer;
    std::vector<uint8_t> currentFrame;

public:
    VideoPlayer(const std::string& name, int x, int y, int w, int h, const std::string& path)
        : Widget(name) {
        setPosition(x, y);
        setSize(w, h);
        videoPath = path;
        logger = std::make_shared<LoggerService>();
        logger->info("Creating VideoPlayer widget with path: " + path);

        // Инициализация размеров и позиций элементов управления
        updateControlsLayout();

        // Создаем декодер и рендерер
        decoder = std::make_unique<VideoDecoder>();
        renderer = std::make_unique<VideoRenderer>();

        // Устанавливаем размер области отображения для рендерера
        renderer->setDisplaySize(w, h - 30); // Оставляем место для элементов управления

        // Если путь к видео задан, пробуем загрузить его
        if (!videoPath.empty()) {
            loadVideo(videoPath);
        }
    }

    ~VideoPlayer() {
        if (font) {
            XftFontClose(currentDisplay, font);
        }
    }

    void loadVideo(const std::string& path) {
        if (decoder->loadVideo(path)) {
            // Устанавливаем размеры видео для рендерера
            renderer->setVideoSize(decoder->getWidth(), decoder->getHeight());

            // Загружаем первый кадр
            currentFrame = decoder->getFirstFrame();

            // Обновляем длительность
            duration = decoder->getDuration() / AV_TIME_BASE; // Конвертируем в секунды

            markDirty();
        } else {
            logger->error("Failed to load video: " + path);
        }
    }

    void setVideoPath(const std::string& path) {
        videoPath = path;
        logger->info("Video path set to: " + videoPath);
        markDirty();
    }

    void play() {
        if (decoder->isLoaded()) {
            isPlaying = true;
            logger->info("Playing video: " + videoPath);
            markDirty();
        } else {
            logger->warning("Cannot play: no video loaded");
        }
    }

    void pause() {
        isPlaying = false;
        logger->info("Paused video: " + videoPath);
        markDirty();
    }

    void togglePlayPause() {
        if (decoder->isLoaded()) {
            isPlaying = !isPlaying;
            logger->info(isPlaying ? "Playing video" : "Paused video");
            markDirty();
        } else {
            logger->warning("Cannot toggle play/pause: no video loaded");
        }
    }

    void setSeekPosition(float pos) {
        // Ограничиваем позицию между 0.0 и 1.0
        currentPosition = std::max(0.0f, std::min(1.0f, pos));
        logger->info("Set position to: " + std::to_string(currentPosition));

        if (decoder->isLoaded()) {
            // Получаем кадр для новой позиции
            currentFrame = decoder->getFrameAtPosition(currentPosition);
        }

        markDirty();
    }

    void handleEvent(const Event& event) override {
        if (event.getType() == Event::Type::MouseDown) {
            int mouseX = event.getX();
            int mouseY = event.getY();

            // Проверка клика на кнопку воспроизведения
            if (mouseX >= controls.playButtonX && mouseX < controls.playButtonX + controls.playButtonWidth &&
                mouseY >= controls.playButtonY && mouseY < controls.playButtonY + controls.playButtonHeight) {
                togglePlayPause();
                return;
                }

            // Проверка клика на прогресс-бар
            if (mouseX >= controls.progressBarX && mouseX < controls.progressBarX + controls.progressBarWidth &&
                mouseY >= controls.progressBarY && mouseY < controls.progressBarY + controls.progressBarHeight) {
                // Вычисляем новую позицию в зависимости от места клика
                float clickPosition = static_cast<float>(mouseX - controls.progressBarX) / controls.progressBarWidth;
                setSeekPosition(clickPosition);
                return;
                }
        }

        return;
    }

    void paintToBuffer(Display* display) override {
        currentDisplay = display;

        if (!font) {
            // Инициализируем шрифт при первой отрисовке
            font = XftFontOpen(display, DefaultScreen(display),
                              XFT_FAMILY, XftTypeString, "DejaVu Sans",
                              XFT_SIZE, XftTypeDouble, 12.0,
                              NULL);

            // Инициализируем цвет текста
            XftColorAllocName(display, DefaultVisual(display, DefaultScreen(display)),
                             DefaultColormap(display, DefaultScreen(display)),
                             "#000000", &textColor);
        }

        auto buffer = getBuffer();
        if (!buffer) return;

        // Рисуем фон
        buffer->fillRectangle(0, 0, getWidth(), getHeight(), 0xEEEEEE);

        // Рисуем область предпросмотра видео
        buffer->fillRectangle(0, 0, getWidth(), getHeight() - 40, 0x333333);

        // Если у нас есть декодированный кадр, рендерим его
        if (!currentFrame.empty() && decoder && decoder->isLoaded()) {
            renderer->renderFrame(currentFrame, *buffer);
        } else {
            // Иначе рисуем черный фон
            if (renderer) {
                renderer->renderBlackBackground(*buffer);
            }
        }

        // Рисуем элементы управления
        drawControls(buffer);

        // Если путь к видео не задан, показываем сообщение
        if (videoPath.empty() || !decoder || !decoder->isLoaded()) {
            // Центрируем текст
            int textX = getWidth() / 2 - 80;
            int textY = getHeight() / 2;

            // Рисуем текст
            buffer->drawText(textX, textY, "No video selected", font, &textColor);
        }
    }

    // Обновляем размеры и позиции элементов управления при изменении размера виджета
    void setWidth(unsigned int newWidth) override {
        Widget::setWidth(newWidth);
        updateControlsLayout();
    }

    void setHeight(unsigned int newHeight) override {
        Widget::setHeight(newHeight);
        updateControlsLayout();
    }

    void setFont(XftFont* newFont) {
        font = newFont;
        updateControlsLayout();
        markDirty();
    }

private:
    void updateControlsLayout() {
        // Кнопка воспроизведения/паузы
        controls.playButtonWidth = 30;
        controls.playButtonHeight = 30;
        controls.playButtonX = 10;
        controls.playButtonY = getHeight() - controls.playButtonHeight - 5;

        // Полоса прогресса
        controls.progressBarHeight = 10;
        controls.progressBarX = controls.playButtonX + controls.playButtonWidth + 10;
        controls.progressBarY = getHeight() - controls.progressBarHeight - 15;
        controls.progressBarWidth = getWidth() - controls.progressBarX - 10;

        // Обновляем размер области отображения для рендерера
        if (renderer) {
            renderer->setDisplaySize(getWidth(), getHeight() - 40);
        }
    }

    void drawControls(RenderBuffer* buffer) {
        // Рисуем кнопку воспроизведения/паузы
        buffer->fillRectangle(controls.playButtonX, controls.playButtonY,
                             controls.playButtonWidth, controls.playButtonHeight,
                             0x4488FF);

        // Рисуем иконку в зависимости от состояния
        if (isPlaying) {
            // Рисуем иконку паузы (две вертикальные линии)
            int pauseX1 = controls.playButtonX + controls.playButtonWidth / 3 - 2;
            int pauseX2 = controls.playButtonX + 2 * controls.playButtonWidth / 3 + 2;
            int pauseY1 = controls.playButtonY + controls.playButtonHeight / 4;
            int pauseY2 = controls.playButtonY + 3 * controls.playButtonHeight / 4;

            buffer->fillRectangle(pauseX1, pauseY1, 4, pauseY2 - pauseY1, 0xFFFFFF);
            buffer->fillRectangle(pauseX2, pauseY1, 4, pauseY2 - pauseY1, 0xFFFFFF);
        } else {
            // Рисуем иконку воспроизведения (треугольник)
            int playX = controls.playButtonX + controls.playButtonWidth / 4;
            int playY = controls.playButtonY + controls.playButtonHeight / 4;
            int playWidth = controls.playButtonWidth / 2;
            int playHeight = controls.playButtonHeight / 2;

            // Простой треугольник (заполненный прямоугольник для простоты)
            buffer->fillRectangle(playX, playY, playWidth, playHeight, 0xFFFFFF);
        }

        // Рисуем фон полосы прогресса
        buffer->fillRectangle(controls.progressBarX, controls.progressBarY,
                             controls.progressBarWidth, controls.progressBarHeight,
                             0xCCCCCC);

        // Рисуем заполненную часть полосы прогресса
        unsigned int filledWidth = static_cast<unsigned int>(currentPosition * controls.progressBarWidth);
        buffer->fillRectangle(controls.progressBarX, controls.progressBarY,
                             filledWidth, controls.progressBarHeight,
                             0x4488FF);
    }
};

================================================================================
FILE: src/ui/video_player/video_renderer.cppm
================================================================================

module;
#include <vector>
#include <memory>
#include <algorithm>

export module ui.video_player.video_renderer;

import ui.render_buffer;
import services.logger_service;

export class VideoRenderer {
private:
    std::shared_ptr<LoggerService> logger;
    int videoWidth = 0;
    int videoHeight = 0;
    int displayWidth = 0;
    int displayHeight = 0;

public:
    VideoRenderer() {
        logger = std::make_shared<LoggerService>();
        logger->info("VideoRenderer created");
    }

    void setVideoSize(int width, int height) {
        videoWidth = width;
        videoHeight = height;
        logger->info("Video size set to: " + std::to_string(width) + "x" + std::to_string(height));
    }

    void setDisplaySize(int width, int height) {
        displayWidth = width;
        displayHeight = height;
        logger->info("Display size set to: " + std::to_string(width) + "x" + std::to_string(height));
    }

    // Рендеринг кадра в буфер
    void renderFrame(const std::vector<uint8_t>& frameData, RenderBuffer& buffer) {
        if (frameData.empty() || videoWidth <= 0 || videoHeight <= 0) {
            logger->warning("Cannot render frame: invalid frame data or dimensions");
            return;
        }

        // Определяем размеры для отображения с сохранением пропорций
        int renderWidth = displayWidth;
        int renderHeight = displayHeight;

        // Если задан размер отображения, вычисляем масштабированные размеры с сохранением пропорций
        if (displayWidth > 0 && displayHeight > 0) {
            double videoAspect = static_cast<double>(videoWidth) / videoHeight;
            double displayAspect = static_cast<double>(displayWidth) / displayHeight;

            if (videoAspect > displayAspect) {
                // Видео шире, чем область отображения
                renderWidth = displayWidth;
                renderHeight = static_cast<int>(displayWidth / videoAspect);
            } else {
                // Видео выше, чем область отображения
                renderHeight = displayHeight;
                renderWidth = static_cast<int>(displayHeight * videoAspect);
            }
        }

        // Вычисляем отступы для центрирования
        int offsetX = (displayWidth - renderWidth) / 2;
        int offsetY = (displayHeight - renderHeight) / 2;

        // Рендерим кадр с масштабированием
        for (int y = 0; y < renderHeight; y++) {
            for (int x = 0; x < renderWidth; x++) {
                // Вычисляем соответствующие координаты в исходном кадре
                int srcX = static_cast<int>(x * videoWidth / renderWidth);
                int srcY = static_cast<int>(y * videoHeight / renderHeight);

                // Вычисляем индекс в массиве данных кадра (RGB формат, 3 байта на пиксель)
                int srcIndex = (srcY * videoWidth + srcX) * 3;

                // Проверяем, что индекс в пределах массива
                if (srcIndex + 2 < frameData.size()) {
                    // Получаем RGB компоненты
                    uint8_t r = frameData[srcIndex];
                    uint8_t g = frameData[srcIndex + 1];
                    uint8_t b = frameData[srcIndex + 2];

                    // Устанавливаем пиксель в буфере
                    // Преобразуем RGB в 32-битный цвет (0xRRGGBB)
                    unsigned long color = (r << 16) | (g << 8) | b;
                    buffer.fillRectangle(offsetX + x, offsetY + y, 1, 1, color);
                }
            }
        }
    }

    // Рендеринг черного фона (для случаев, когда нет кадра)
    void renderBlackBackground(RenderBuffer& buffer) {
        // Черный цвет - 0x000000
        buffer.fillRectangle(0, 0, displayWidth, displayHeight, 0x000000);
    }
};

